# Betanítási költség, túltanulás, alultanulás, neuron

<!--toc:start-->
- [Betanítási költség, túltanulás, alultanulás, neuron](#betanítási-költség-túltanulás-alultanulás-neuron)
  - [Lineáris regresszió](#lineáris-regresszió)
  - [A minta felosztása](#a-minta-felosztása)
  - [A költség alakulása a betanítás során](#a-költség-alakulása-a-betanítás-során)
    - [Alultanulás:](#alultanulás)
    - [Túltanulás](#túltanulás)
    - [Alultanulás és túltanulás elkerülése](#alultanulás-és-túltanulás-elkerülése)
  - [Betanítás folyamata](#betanítás-folyamata)
  - [Neuron](#neuron)
  - [Források](#források)
<!--toc:end-->

## Lineáris regresszió
- A lineáris regresszió jól működik olyan mintán, ahol a változók lineáris kombinációja jól közrlíti a mintát.
- Mit tehetünk, ha ez nem áll fenn?
- Pl.: Polinómiális regresszió (a mintákat hatványozzuk, amit keresünk, azok az együtthatók)
  - Lineáris regresszióként megoldhatjuk, ha behelyettesítjük az előre kiszámolt változók hatványokat.
  - Az új változókra alkalmazhatunk feature-scaling-et, hogy csökkentsük a hatványozás okozta nagyságrendi problémákat.

## A minta felosztása
Modell életciklusa:
1. training set
2. test set
3. validation set

## A költség alakulása a betanítás során
### Alultanulás:
- Pl. ha polinomiális regresszió során túl alacsony fokú polinomot használunk, vagy kicsi, vagy "fura" a training set
- A teszt hiba (és a training is) nagy.
### Túltanulás
- Pl. Ha túl kicsi a training set, és specializálódik a model erre a training set-re
- A training set hiba javul, de a teszt set-en nem változik, vagy nő
- Így a model nem lesz elég generikus

### Alultanulás és túltanulás elkerülése
- **Alultanulás:** A modell komplexitása túl kicsi, bonnyolultabb modell szükséges.
- **Túltanulás:**
  - A modell elég összetett ahhoz, hogy pontosan a tanítóhalmaz egyes elemeinek sajátosságaira fixál rá.
  - A modell komplexitását is csökkenthetjük, de ez nem kívánatos.
  - (L2) Regularizáció: hatalmas együtthatók csökkentése: a költségfüggvény büntesse a nagy együtthatókat (azoknak a négyzetüket).
  - Early stopping: Amikor a teszt halmazon mért költség elkezd nőni, akkor megálunk.
    - Ilyenkor a teszthalmazt is belevontuk a tanulásban (big no-no)
    - Ilyenkor használunk egy validációs halmazt is, amit a teszt halmaz helyett vonunk be.
    - A validációs halmazzal optimalizáljuk a "hiperparamétereket"

## Betanítás folyamata
1. hiperparaméterek konfigurációja
2. paraméterek optimalizálása, hiperparaméterek megváltoztatása
3. teszt futtatása, hibamérés

## Neuron
- Bemenetek $\to$ kimenetek (konstans jel)
- A bemenetekből egy lépcsőfüggvényel kapjuk meg a konstans kimenetet
- Együttható
- Bias
- Aktivációs függvény
  - pl. sigmoid
    
## Források
- [Diasor](TBA)
